{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSUUHwFxKtuf",
        "outputId": "3d54b726-9325-403c-a61b-f7f338e005a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKNXAbiCK1ls",
        "outputId": "32300886-7219-41c9-9933-c9cd36bc7acd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['colab_pipeline.ipynb', 'dataset_info.ipynb', 'mp4_to_avi.ipynb', 'pileline.ipynb']\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import time\n",
        "\n",
        "zip_file = \"/root/videos.zip\"\n",
        "z = zipfile.ZipFile(zip_file, \"r\")\n",
        "z.extractall(\"/root/videos\")\n",
        "\n",
        "print(os.listdir())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rzzF1OWirl7"
      },
      "outputs": [],
      "source": [
        "!pip install \"git+https://github.com/facebookresearch/pytorchvideo.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CEsTq2MLNvc",
        "outputId": "daa3d48e-eb15-47de-c21c-ec2f85edad62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing collected packages: smmap, setproctitle, sentry-sdk, pyarrow-hotfix, docker-pycreds, dill, responses, multiprocess, gitdb, GitPython, accelerate, wandb, datasets, evaluate\n",
            "Successfully installed GitPython-3.1.40 accelerate-0.24.1 datasets-2.15.0 dill-0.3.7 docker-pycreds-0.4.0 evaluate-0.4.1 gitdb-4.0.11 multiprocess-0.70.15 pyarrow-hotfix-0.6 responses-0.18.0 sentry-sdk-1.37.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb accelerate transformers imageio evaluate # pytorchvideo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLhaReI48q2H"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wBn7GCobL5Ep"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pytorchvideo.data\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import VideoMAEImageProcessor, VideoMAEForVideoClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import evaluate\n",
        "\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey,\n",
        "    Normalize,\n",
        "    RandomShortSideScale,\n",
        "    RemoveKey,\n",
        "    ShortSideScale,\n",
        "    UniformTemporalSubsample,\n",
        "    MixUp,\n",
        ")\n",
        "\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "from torchvision.transforms import (\n",
        "    Compose,\n",
        "    Lambda,\n",
        "    RandomCrop,\n",
        "    RandomHorizontalFlip,\n",
        "    Resize,\n",
        ")\n",
        "\n",
        "import imageio\n",
        "import numpy as np\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtufgwN-WG_L"
      },
      "source": [
        "## Delete broken samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v0xKy2aNJT6D"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "def check_video(file_path):\n",
        "    \"\"\" Проверяет видеофайл на повреждения с помощью FFmpeg. \"\"\"\n",
        "    try:\n",
        "        result = subprocess.run(['ffmpeg', '-v', 'error', '-i', file_path, '-f', 'null', '-'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        return result.stderr\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "def scan_directory(directory):\n",
        "    \"\"\" Сканирует директорию на наличие поврежденных видеофайлов. \"\"\"\n",
        "    failed_files = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith('.mp4'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                error = check_video(file_path)\n",
        "                if error:\n",
        "                    failed_files.append(file_path)\n",
        "                    print(f\"Поврежденный файл: {file_path}\\nОшибка: {error}\")\n",
        "    return failed_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kDeW8nalJeFI"
      },
      "outputs": [],
      "source": [
        "# Проверяем директории videos/train и videos/val\n",
        "train_failed = scan_directory('/content/home/myashka/dl_programming_tech/coin_dataset_classification/data/videos/train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hViGBGAZJqLd"
      },
      "outputs": [],
      "source": [
        "val_failed = scan_directory('/content/videos/val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ORNHSnATU98D"
      },
      "outputs": [],
      "source": [
        "train_damaged_videos = [\n",
        "    \"/content/videos/train/ElectricalAppliance/CSGi2mBh0Os.mp4\",\n",
        "    \"/content/videos/train/ElectricalAppliance/TDm3IX_0gLQ.mp4\",\n",
        "    \"/content/videos/train/Housework/b9LBMy8_3-E.mp4\",\n",
        "    \"/content/videos/train/Vehicle/Y9u-zmH6yz0.mp4\",\n",
        "    \"/content/videos/train/Vehicle/3R8KgG-0X_Q.mp4\",\n",
        "    \"/content/videos/train/Dish/XMXsVSchsWc.mp4\",\n",
        "    \"/content/videos/train/FurnitureandDecoration/8ed8DjTm7VQ.mp4\",\n",
        "    \"/content/videos/train/FurnitureandDecoration/fP8zX6UKsRA.mp4\",\n",
        "    \"/content/videos/train/FurnitureandDecoration/Ntzsfe0xzF8.mp4\",\n",
        "    \"/content/videos/train/LeisureandPerformance/8SWBWxqXulE.mp4\",\n",
        "    \"/content/videos/train/LeisureandPerformance/m2TDD-ogwog.mp4\",\n",
        "    \"/content/videos/train/LeisureandPerformance/IjwP6hRFaI8.mp4\",\n",
        "    \"/content/videos/train/LeisureandPerformance/tpNZUJVo3bQ.mp4\",\n",
        "    \"/content/videos/train/LeisureandPerformance/pLlk2ahyNgs.mp4\",\n",
        "    \"/content/videos/train/NursingandCare/9O63JaEPrTA.mp4\",\n",
        "    \"/content/videos/train/Gadgets/ut5HYK4g7KA.mp4\",\n",
        "    \"/content/videos/train/Gadgets/l8JneKWvYrU.mp4\",\n",
        "    \"/content/videos/train/Gadgets/iD0QvQyhGSA.mp4\",\n",
        "    \"/content/videos/train/Gadgets/48pfFiR6ras.mp4\",\n",
        "    \"/content/videos/train/Sport/wPGxAEkjBmY.mp4\",\n",
        "    \"/content/videos/train/Sport/NLy71UrHElw.mp4\",\n",
        "    \"/content/videos/train/Sport/kJ1JSGamJD4.mp4\",\n",
        "    \"/content/videos/train/Sport/grptW7-6Jdg.mp4\"\n",
        "]\n",
        "\n",
        "val_damaged_videos = [\"/content/videos/val/Housework/2ESPauwYUnQ.mp4\",\n",
        "                      \"/content/videos/val/ScienceandCraft/plqx50x8ft4.mp4\",\n",
        "                      \"/content/videos/val/LeisureandPerformance/dkDUFlHIh64.mp4\",\n",
        "                      \"/content/videos/val/NursingandCare/WBC8koF-oDQ.mp4\",\n",
        "                      \"/content/videos/val/Gadgets/s2HN0X5BLrQ.mp4\",\n",
        "                      \"/content/videos/val/DrinkandSnack/GamLf68iz0E.mp4\",\n",
        "                      \"/content/videos/val/Sport/DhuidqjsWmo.mp4\",\n",
        "                      \"/content/videos/val/Sport/jhYtXcbWPgY.mp4\"\n",
        "                      ]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xomn_WPvWm-N"
      },
      "outputs": [],
      "source": [
        "def delete_files(paths):\n",
        "  for video_path in paths:\n",
        "      if os.path.exists(video_path):\n",
        "          os.remove(video_path)\n",
        "          print(f\"Удален файл: {video_path}\")\n",
        "      else:\n",
        "          print(f\"Файл не найден: {video_path}\")\n",
        "\n",
        "delete_files(train_damaged_videos)\n",
        "delete_files(val_damaged_videos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlJXBE5-WAxK",
        "outputId": "3e7ae473-f2f2-4be1-d7d5-f22361339356"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vehicle: 73 видео\n",
            "ElectricalAppliance: 70 видео\n",
            "Sport: 85 видео\n",
            "Dish: 70 видео\n",
            "ScienceandCraft: 37 видео\n",
            "Gadgets: 99 видео\n",
            "Housework: 80 видео\n",
            "PetsandFruit: 28 видео\n",
            "DrinkandSnack: 34 видео\n",
            "NursingandCare: 69 видео\n",
            "FurnitureandDecoration: 45 видео\n",
            "LeisureandPerformance: 75 видео\n"
          ]
        }
      ],
      "source": [
        "# Подсчет оставшихся видео в каждой категории\n",
        "category_counts = {}\n",
        "\n",
        "train_dir = '/content/videos/train'\n",
        "for category in os.listdir(train_dir):\n",
        "    category_path = os.path.join(train_dir, category)\n",
        "    if os.path.isdir(category_path):\n",
        "        videos = [video for video in os.listdir(category_path) if video.endswith('.mp4')]\n",
        "        category_counts[category] = len(videos)\n",
        "\n",
        "# Вывод количества видео по категориям\n",
        "for category, count in category_counts.items():\n",
        "    print(f\"{category}: {count} видео\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tf3hlmlW2sM",
        "outputId": "6a2b02ab-c653-4b7e-ab3a-dcb049c264f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vehicle: 31 видео\n",
            "ElectricalAppliance: 13 видео\n",
            "Sport: 18 видео\n",
            "Dish: 20 видео\n",
            "ScienceandCraft: 16 видео\n",
            "Gadgets: 36 видео\n",
            "Housework: 28 видео\n",
            "PetsandFruit: 13 видео\n",
            "DrinkandSnack: 13 видео\n",
            "NursingandCare: 22 видео\n",
            "FurnitureandDecoration: 11 видео\n",
            "LeisureandPerformance: 24 видео\n"
          ]
        }
      ],
      "source": [
        "# Подсчет оставшихся видео в каждой категории\n",
        "category_counts = {}\n",
        "\n",
        "train_dir = '/content/videos/val'\n",
        "for category in os.listdir(train_dir):\n",
        "    category_path = os.path.join(train_dir, category)\n",
        "    if os.path.isdir(category_path):\n",
        "        videos = [video for video in os.listdir(category_path) if video.endswith('.mp4')]\n",
        "        category_counts[category] = len(videos)\n",
        "\n",
        "# Вывод количества видео по категориям\n",
        "for category, count in category_counts.items():\n",
        "    print(f\"{category}: {count} видео\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRx80VOSWCFK"
      },
      "source": [
        "## Train Pipeline starting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8i0qRu7gMCcT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique classes 12: ['Dish', 'DrinkandSnack', 'ElectricalAppliance', 'FurnitureandDecoration', 'Gadgets', 'Housework', 'LeisureandPerformance', 'NursingandCare', 'PetsandFruit', 'ScienceandCraft', 'Sport', 'Vehicle'].\n"
          ]
        }
      ],
      "source": [
        "class_labels = sorted(os.listdir(\"/root/videos/home/myashka/dl_programming_tech/coin_dataset_classification/data/videos/train\"))\n",
        "label2id = {label: i for i, label in enumerate(class_labels)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "print(f\"Unique classes {len(list(label2id.keys()))}: {list(label2id.keys())}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asPM_q0tCOlB",
        "outputId": "13496fef-19eb-4b05-ac9c-346b9c4a44d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'': 0}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
        "device_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "81TQy8YEKv9_"
      },
      "outputs": [],
      "source": [
        "from transformers import VideoMAEConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "8e7544525d3b460387090654afeaf86d",
            "a47b4b36108c4306ad4cfc9040124d8d",
            "60668640dbf14745a79a1724c73676e7",
            "6c358a8c61eb457cb2eb4cff64eea8af",
            "251a77c309a74517a351a28a030a2335",
            "d61dea3231064c2d94ebed59fa6ee66a",
            "05e80d2e20ed4e2abcd439058f60f971",
            "d229a5af4a67402aa814744dc47eb9a7",
            "e73941a8a36446fd9e312a0aeff505a2",
            "a20c1548c2a646649031657d9026f261",
            "7e262ccea14d4a88aeba43ccc1a30b5a",
            "cec437841a924e1baa4858498868bf80",
            "2f95154f9023414caea9921833e61db0",
            "fcc1675ee5604a90ac7327dd889be3cc",
            "91f23da2987d42b1829218bc9a156839",
            "e49c4e279ec447a8afa1a1ad88df0fb0",
            "18a1811e259f411584bbb7e188470878",
            "04321b9477b649eaa7f738e3a6da84a8",
            "027b16d7da0c48c5a46de46f32550ebb",
            "6f211880114245929256e35b2314e594",
            "5041c2d4be1840c59a72c93ded2a7857",
            "befa5ba440b0426ab189b2f53d22c134"
          ]
        },
        "id": "Yh8aRcEIK--i",
        "outputId": "ea158fbb-b357-4097-811b-47897483c268"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base and are newly initialized: ['fc_norm.bias', 'classifier.bias', 'fc_norm.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_ckpt = \"MCG-NJU/videomae-base\"\n",
        "config = VideoMAEConfig(image_size=224,\n",
        "                        label2id=label2id,\n",
        "                        id2label=id2label,\n",
        "                        ignore_mismatched_sizes=True)\n",
        "image_processor = VideoMAEImageProcessor.from_pretrained(model_ckpt, config=config)\n",
        "\n",
        "model = VideoMAEForVideoClassification.from_pretrained(\n",
        "    model_ckpt,\n",
        "    config=config,\n",
        "    # torch_dtype=torch.float16,\n",
        "    device_map=device_map,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "y043-UQmFKz8"
      },
      "outputs": [],
      "source": [
        "# image_processor.size['shortest_edge'] = 112\n",
        "# model.config.image_size = 112"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hnuUlQEMO00",
        "outputId": "d028dd70-6440-4a79-d087-346410ae194a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean: [0.485, 0.456, 0.406]\n",
            "Std: [0.229, 0.224, 0.225]\n",
            "Resize to (224, 224)\n",
            "Num frames to sample: 16\n",
            "Sample rate: 4\n",
            "Duration: 2.1333333333333333 sec\n"
          ]
        }
      ],
      "source": [
        "mean = image_processor.image_mean\n",
        "std = image_processor.image_std\n",
        "print(f\"Mean: {mean}\\nStd: {std}\")\n",
        "if \"shortest_edge\" in image_processor.size:\n",
        "    height = width = image_processor.size[\"shortest_edge\"]\n",
        "else:\n",
        "    height = image_processor.size[\"height\"]\n",
        "    width = image_processor.size[\"width\"]\n",
        "resize_to = (height, width)\n",
        "print(f\"Resize to {resize_to}\")\n",
        "\n",
        "num_frames_to_sample = model.config.num_frames\n",
        "sample_rate = 4\n",
        "fps = 30\n",
        "clip_duration = num_frames_to_sample * sample_rate / fps\n",
        "print(f\"Num frames to sample: {num_frames_to_sample}\")\n",
        "print(f\"Sample rate: {sample_rate}\")\n",
        "print(f\"Duration: {clip_duration} sec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mH3mFdy5MXzv"
      },
      "outputs": [],
      "source": [
        "train_transform = v2.Compose(\n",
        "    [\n",
        "        ApplyTransformToKey(\n",
        "            key=\"video\",\n",
        "            transform=v2.Compose(\n",
        "                [\n",
        "                    UniformTemporalSubsample(num_frames_to_sample),\n",
        "                    v2.Lambda(lambda x: x / 255.0),\n",
        "                    Normalize(mean, std),\n",
        "                    RandomShortSideScale(min_size=224, max_size=320),\n",
        "                    v2.RandomCrop(resize_to),\n",
        "                    v2.RandomHorizontalFlip(p=0.5),\n",
        "                ]\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transform = v2.Compose(\n",
        "    [\n",
        "        ApplyTransformToKey(\n",
        "            key=\"video\",\n",
        "            transform=v2.Compose(\n",
        "                [\n",
        "                    UniformTemporalSubsample(num_frames_to_sample),\n",
        "                    v2.Lambda(lambda x: x / 255.0),\n",
        "                    Normalize(mean, std),\n",
        "                    v2.Resize(resize_to),\n",
        "                ]\n",
        "            ),\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EOH_UPkZMc3E"
      },
      "outputs": [],
      "source": [
        "dataset_root_path = \"/root/videos/home/myashka/dl_programming_tech/coin_dataset_classification/data/videos/\"\n",
        "train_dataset = pytorchvideo.data.Ucf101(\n",
        "    data_path=os.path.join(dataset_root_path, \"train\"),\n",
        "    clip_sampler=pytorchvideo.data.make_clip_sampler(\"random\", clip_duration),\n",
        "    decode_audio=False,\n",
        "    transform=train_transform,\n",
        ")\n",
        "\n",
        "val_dataset = pytorchvideo.data.Ucf101(\n",
        "    data_path=os.path.join(dataset_root_path, \"val\"),\n",
        "    clip_sampler=pytorchvideo.data.make_clip_sampler(\"random\", clip_duration),\n",
        "    decode_audio=False,\n",
        "    transform=val_transform,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kph5IZqtMpQM",
        "outputId": "f2eb1986-137d-41c2-bf47-14a5482a032a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "787 253\n",
            "Test data: 24.33%\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset.num_videos, val_dataset.num_videos)\n",
        "print(f'Test data: {round(val_dataset.num_videos/(train_dataset.num_videos+val_dataset.num_videos)*100, 2)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8m_3V3M5MsU3"
      },
      "outputs": [],
      "source": [
        "def unnormalize_img(img):\n",
        "    \"\"\"Un-normalizes the image pixels.\"\"\"\n",
        "    img = (img * std) + mean\n",
        "    img = (img * 255).astype(\"uint8\")\n",
        "    return img.clip(0, 255)\n",
        "\n",
        "def create_gif(video_tensor, filename=\"sample.gif\"):\n",
        "    \"\"\"Prepares a GIF from a video tensor.\n",
        "\n",
        "    The video tensor is expected to have the following shape:\n",
        "    (num_frames, num_channels, height, width).\n",
        "    \"\"\"\n",
        "    frames = []\n",
        "    for video_frame in video_tensor:\n",
        "        frame_unnormalized = unnormalize_img(video_frame.permute(1, 2, 0).numpy())\n",
        "        frames.append(frame_unnormalized)\n",
        "    kargs = {\"duration\": 0.25}\n",
        "    imageio.mimsave(filename, frames, \"GIF\", **kargs)\n",
        "    return filename\n",
        "\n",
        "def display_gif(video_tensor, gif_name=\"sample.gif\"):\n",
        "    \"\"\"Prepares and displays a GIF from a video tensor.\"\"\"\n",
        "    video_tensor = video_tensor.permute(1, 0, 2, 3)\n",
        "    gif_filename = create_gif(video_tensor, gif_name)\n",
        "    return Image(filename=gif_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "FJvpqf3SIh9G",
        "outputId": "cf1e188d-b388-485b-d7da-6b38f682c773"
      },
      "outputs": [
        {
          "data": {
            "image/gif": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_video = next(train_dataset)\n",
        "video_tensor = sample_video[\"video\"]\n",
        "display_gif(video_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "z12_eS9sMt6r"
      },
      "outputs": [],
      "source": [
        "# mix_up = MixUp(0.7, num_classes=12)\n",
        "def collate_fn(examples):\n",
        "    pixel_values_list = [example[\"video\"].permute(1, 0, 2, 3) for example in examples]\n",
        "    labels_list = [example[\"label\"] for example in examples]\n",
        "\n",
        "    pixel_values = torch.stack(pixel_values_list)\n",
        "    labels = torch.tensor(labels_list)\n",
        "\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "    # pixel_values = torch.stack(\n",
        "    #     [example[\"video\"] for example in examples]\n",
        "    # )\n",
        "    # labels = torch.tensor([example[\"label\"] for example in examples])\n",
        "    # pixel_values, labels = mix_up(pixel_values, labels)\n",
        "    # # permute to (num_frames, num_channels, height, width)\n",
        "    # pixel_values = torch.stack(\n",
        "    #     [pixel_value.permute(1, 0, 2, 3) for pixel_value in pixel_values]\n",
        "    # )\n",
        "    # labels = torch.argmax(labels, axis=1)\n",
        "    # return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "58712dabfef24eb9835a3fbd1e54845d",
            "dc7da12d370f48ab952ef4f922b502c7",
            "f105eb1da0fb44f5a39ed92bbd327f57",
            "2843b0d1ed0945cc8def7a9bbc04ec98",
            "11519a296deb4b8d844096340246ca4b",
            "b37c24d7a5924eb9a90343f848e3cb76",
            "6f980a3f470b44ff9cc3406842214427",
            "1a82fe71bda54ec38e3134e6c828c2c1",
            "8c80069bdbc04e70a3b2e27371de5599",
            "3b5475dce1ba49f3b34bd5faffe4a576",
            "164a753ddf594b37bb4ad9ece7b291de",
            "506761dd1d85471b8f73fc07fbe5eb93",
            "7aab1a2b0da64bf496e1e23e0fc2552b",
            "db004e1b87b04aa98361b20cafe49e48",
            "fe57d4e345824755ba9da003b2496b81",
            "dd36a048c4984354a3d3242271ded2eb",
            "dd88a07c1ac64ac7b6833e3acda081a5",
            "990864af312e4c45b1688a179657b549",
            "cbcce07dd5504cb6a0b477a323522984",
            "42f4e6c969504bc6b5b0b691505c8ba2",
            "90df514de1a4453aadaa94b41ede6321",
            "23fb2075cf8e46d28996f84175f7d120",
            "ae04bac7cac54b32a5c2ddf350dd1ff3",
            "c442e80d94334615bc94b25a776894f7",
            "7662a9be4ddc4914820bea466a5c0c16",
            "455d1afe2fd54f23a01c3cb73b9fa16e",
            "c59875cce0424b0e80e81c41639cc195",
            "ef6dceb2f45543efa73bb6f9d2c5a124",
            "2b7e94237f574e6a97498cba9e5bd798",
            "e90da3ea3976461d998d51d729bf38fe",
            "eb780556aa8341b48c6dd6345174a40a",
            "67287112196c4f199b87117490e463be",
            "1aa64526684d4f4e9617e3c5de9dd9b7",
            "d4257ae2406a46cd8de56343b113ab72",
            "e54ebd8ee7ba4c57a02677d4d3ec00ec",
            "68cd1222ff9342c69e2e0463d532eece",
            "ff2dae68d156444fa75285138b4ada8d",
            "6c2dafd262e7426ab627e77f0ea3613a",
            "1c7e434be8f54bb19430b0554d6cdbc9",
            "d84b39329eae493680f78e6306b6caf0",
            "a0e25554548447c4b104affd8c3c9d5b",
            "adad6ac7dd424726a1e462d8715cc421",
            "97667e143c4a4b048811cc7a84ee74c9",
            "30513adbebbb4c1eaf03120ffdd98c09"
          ]
        },
        "id": "9h29wX9FM6h8",
        "outputId": "ec307bf7-6686-41dd-b0b3-e4284cb3ce3f"
      },
      "outputs": [],
      "source": [
        "f1_metric = evaluate.load(\"f1\")\n",
        "precision_metric = evaluate.load(\"precision\")\n",
        "recall_metric = evaluate.load(\"recall\")\n",
        "accuracy_metric = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Qvt0z_txNTs3"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    preds = np.argmax(eval_pred.predictions, axis=1)\n",
        "    labels = eval_pred.label_ids\n",
        "    results = {}\n",
        "    results.update(f1_metric.compute(predictions=preds, references = labels, average=\"micro\"))\n",
        "    results.update(precision_metric.compute(predictions=preds, references = labels, average=\"micro\"))\n",
        "    results.update(recall_metric.compute(predictions=preds, references = labels, average=\"micro\"))\n",
        "    results.update(accuracy_metric.compute(predictions=preds, references = labels))\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ztOcY1VSNggm"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_PROJECT\"] = \"ITMO_Video_lab\"\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "L7BW-nuDAabV"
      },
      "outputs": [],
      "source": [
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# for param in model.classifier.parameters():\n",
        "#     param.requires_grad = True\n",
        "# for param in model.videomae.encoder.layer[-1].parameters():\n",
        "#     param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w07YAJwzClGj",
        "outputId": "86a3d35a-dd3e-4586-cd20-9168aec8f76d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "videomae.embeddings.patch_embeddings.projection.weight\n",
            "videomae.embeddings.patch_embeddings.projection.bias\n",
            "videomae.encoder.layer.0.attention.attention.q_bias\n",
            "videomae.encoder.layer.0.attention.attention.v_bias\n",
            "videomae.encoder.layer.0.attention.attention.query.weight\n",
            "videomae.encoder.layer.0.attention.attention.key.weight\n",
            "videomae.encoder.layer.0.attention.attention.value.weight\n",
            "videomae.encoder.layer.0.attention.output.dense.weight\n",
            "videomae.encoder.layer.0.attention.output.dense.bias\n",
            "videomae.encoder.layer.0.intermediate.dense.weight\n",
            "videomae.encoder.layer.0.intermediate.dense.bias\n",
            "videomae.encoder.layer.0.output.dense.weight\n",
            "videomae.encoder.layer.0.output.dense.bias\n",
            "videomae.encoder.layer.0.layernorm_before.weight\n",
            "videomae.encoder.layer.0.layernorm_before.bias\n",
            "videomae.encoder.layer.0.layernorm_after.weight\n",
            "videomae.encoder.layer.0.layernorm_after.bias\n",
            "videomae.encoder.layer.1.attention.attention.q_bias\n",
            "videomae.encoder.layer.1.attention.attention.v_bias\n",
            "videomae.encoder.layer.1.attention.attention.query.weight\n",
            "videomae.encoder.layer.1.attention.attention.key.weight\n",
            "videomae.encoder.layer.1.attention.attention.value.weight\n",
            "videomae.encoder.layer.1.attention.output.dense.weight\n",
            "videomae.encoder.layer.1.attention.output.dense.bias\n",
            "videomae.encoder.layer.1.intermediate.dense.weight\n",
            "videomae.encoder.layer.1.intermediate.dense.bias\n",
            "videomae.encoder.layer.1.output.dense.weight\n",
            "videomae.encoder.layer.1.output.dense.bias\n",
            "videomae.encoder.layer.1.layernorm_before.weight\n",
            "videomae.encoder.layer.1.layernorm_before.bias\n",
            "videomae.encoder.layer.1.layernorm_after.weight\n",
            "videomae.encoder.layer.1.layernorm_after.bias\n",
            "videomae.encoder.layer.2.attention.attention.q_bias\n",
            "videomae.encoder.layer.2.attention.attention.v_bias\n",
            "videomae.encoder.layer.2.attention.attention.query.weight\n",
            "videomae.encoder.layer.2.attention.attention.key.weight\n",
            "videomae.encoder.layer.2.attention.attention.value.weight\n",
            "videomae.encoder.layer.2.attention.output.dense.weight\n",
            "videomae.encoder.layer.2.attention.output.dense.bias\n",
            "videomae.encoder.layer.2.intermediate.dense.weight\n",
            "videomae.encoder.layer.2.intermediate.dense.bias\n",
            "videomae.encoder.layer.2.output.dense.weight\n",
            "videomae.encoder.layer.2.output.dense.bias\n",
            "videomae.encoder.layer.2.layernorm_before.weight\n",
            "videomae.encoder.layer.2.layernorm_before.bias\n",
            "videomae.encoder.layer.2.layernorm_after.weight\n",
            "videomae.encoder.layer.2.layernorm_after.bias\n",
            "videomae.encoder.layer.3.attention.attention.q_bias\n",
            "videomae.encoder.layer.3.attention.attention.v_bias\n",
            "videomae.encoder.layer.3.attention.attention.query.weight\n",
            "videomae.encoder.layer.3.attention.attention.key.weight\n",
            "videomae.encoder.layer.3.attention.attention.value.weight\n",
            "videomae.encoder.layer.3.attention.output.dense.weight\n",
            "videomae.encoder.layer.3.attention.output.dense.bias\n",
            "videomae.encoder.layer.3.intermediate.dense.weight\n",
            "videomae.encoder.layer.3.intermediate.dense.bias\n",
            "videomae.encoder.layer.3.output.dense.weight\n",
            "videomae.encoder.layer.3.output.dense.bias\n",
            "videomae.encoder.layer.3.layernorm_before.weight\n",
            "videomae.encoder.layer.3.layernorm_before.bias\n",
            "videomae.encoder.layer.3.layernorm_after.weight\n",
            "videomae.encoder.layer.3.layernorm_after.bias\n",
            "videomae.encoder.layer.4.attention.attention.q_bias\n",
            "videomae.encoder.layer.4.attention.attention.v_bias\n",
            "videomae.encoder.layer.4.attention.attention.query.weight\n",
            "videomae.encoder.layer.4.attention.attention.key.weight\n",
            "videomae.encoder.layer.4.attention.attention.value.weight\n",
            "videomae.encoder.layer.4.attention.output.dense.weight\n",
            "videomae.encoder.layer.4.attention.output.dense.bias\n",
            "videomae.encoder.layer.4.intermediate.dense.weight\n",
            "videomae.encoder.layer.4.intermediate.dense.bias\n",
            "videomae.encoder.layer.4.output.dense.weight\n",
            "videomae.encoder.layer.4.output.dense.bias\n",
            "videomae.encoder.layer.4.layernorm_before.weight\n",
            "videomae.encoder.layer.4.layernorm_before.bias\n",
            "videomae.encoder.layer.4.layernorm_after.weight\n",
            "videomae.encoder.layer.4.layernorm_after.bias\n",
            "videomae.encoder.layer.5.attention.attention.q_bias\n",
            "videomae.encoder.layer.5.attention.attention.v_bias\n",
            "videomae.encoder.layer.5.attention.attention.query.weight\n",
            "videomae.encoder.layer.5.attention.attention.key.weight\n",
            "videomae.encoder.layer.5.attention.attention.value.weight\n",
            "videomae.encoder.layer.5.attention.output.dense.weight\n",
            "videomae.encoder.layer.5.attention.output.dense.bias\n",
            "videomae.encoder.layer.5.intermediate.dense.weight\n",
            "videomae.encoder.layer.5.intermediate.dense.bias\n",
            "videomae.encoder.layer.5.output.dense.weight\n",
            "videomae.encoder.layer.5.output.dense.bias\n",
            "videomae.encoder.layer.5.layernorm_before.weight\n",
            "videomae.encoder.layer.5.layernorm_before.bias\n",
            "videomae.encoder.layer.5.layernorm_after.weight\n",
            "videomae.encoder.layer.5.layernorm_after.bias\n",
            "videomae.encoder.layer.6.attention.attention.q_bias\n",
            "videomae.encoder.layer.6.attention.attention.v_bias\n",
            "videomae.encoder.layer.6.attention.attention.query.weight\n",
            "videomae.encoder.layer.6.attention.attention.key.weight\n",
            "videomae.encoder.layer.6.attention.attention.value.weight\n",
            "videomae.encoder.layer.6.attention.output.dense.weight\n",
            "videomae.encoder.layer.6.attention.output.dense.bias\n",
            "videomae.encoder.layer.6.intermediate.dense.weight\n",
            "videomae.encoder.layer.6.intermediate.dense.bias\n",
            "videomae.encoder.layer.6.output.dense.weight\n",
            "videomae.encoder.layer.6.output.dense.bias\n",
            "videomae.encoder.layer.6.layernorm_before.weight\n",
            "videomae.encoder.layer.6.layernorm_before.bias\n",
            "videomae.encoder.layer.6.layernorm_after.weight\n",
            "videomae.encoder.layer.6.layernorm_after.bias\n",
            "videomae.encoder.layer.7.attention.attention.q_bias\n",
            "videomae.encoder.layer.7.attention.attention.v_bias\n",
            "videomae.encoder.layer.7.attention.attention.query.weight\n",
            "videomae.encoder.layer.7.attention.attention.key.weight\n",
            "videomae.encoder.layer.7.attention.attention.value.weight\n",
            "videomae.encoder.layer.7.attention.output.dense.weight\n",
            "videomae.encoder.layer.7.attention.output.dense.bias\n",
            "videomae.encoder.layer.7.intermediate.dense.weight\n",
            "videomae.encoder.layer.7.intermediate.dense.bias\n",
            "videomae.encoder.layer.7.output.dense.weight\n",
            "videomae.encoder.layer.7.output.dense.bias\n",
            "videomae.encoder.layer.7.layernorm_before.weight\n",
            "videomae.encoder.layer.7.layernorm_before.bias\n",
            "videomae.encoder.layer.7.layernorm_after.weight\n",
            "videomae.encoder.layer.7.layernorm_after.bias\n",
            "videomae.encoder.layer.8.attention.attention.q_bias\n",
            "videomae.encoder.layer.8.attention.attention.v_bias\n",
            "videomae.encoder.layer.8.attention.attention.query.weight\n",
            "videomae.encoder.layer.8.attention.attention.key.weight\n",
            "videomae.encoder.layer.8.attention.attention.value.weight\n",
            "videomae.encoder.layer.8.attention.output.dense.weight\n",
            "videomae.encoder.layer.8.attention.output.dense.bias\n",
            "videomae.encoder.layer.8.intermediate.dense.weight\n",
            "videomae.encoder.layer.8.intermediate.dense.bias\n",
            "videomae.encoder.layer.8.output.dense.weight\n",
            "videomae.encoder.layer.8.output.dense.bias\n",
            "videomae.encoder.layer.8.layernorm_before.weight\n",
            "videomae.encoder.layer.8.layernorm_before.bias\n",
            "videomae.encoder.layer.8.layernorm_after.weight\n",
            "videomae.encoder.layer.8.layernorm_after.bias\n",
            "videomae.encoder.layer.9.attention.attention.q_bias\n",
            "videomae.encoder.layer.9.attention.attention.v_bias\n",
            "videomae.encoder.layer.9.attention.attention.query.weight\n",
            "videomae.encoder.layer.9.attention.attention.key.weight\n",
            "videomae.encoder.layer.9.attention.attention.value.weight\n",
            "videomae.encoder.layer.9.attention.output.dense.weight\n",
            "videomae.encoder.layer.9.attention.output.dense.bias\n",
            "videomae.encoder.layer.9.intermediate.dense.weight\n",
            "videomae.encoder.layer.9.intermediate.dense.bias\n",
            "videomae.encoder.layer.9.output.dense.weight\n",
            "videomae.encoder.layer.9.output.dense.bias\n",
            "videomae.encoder.layer.9.layernorm_before.weight\n",
            "videomae.encoder.layer.9.layernorm_before.bias\n",
            "videomae.encoder.layer.9.layernorm_after.weight\n",
            "videomae.encoder.layer.9.layernorm_after.bias\n",
            "videomae.encoder.layer.10.attention.attention.q_bias\n",
            "videomae.encoder.layer.10.attention.attention.v_bias\n",
            "videomae.encoder.layer.10.attention.attention.query.weight\n",
            "videomae.encoder.layer.10.attention.attention.key.weight\n",
            "videomae.encoder.layer.10.attention.attention.value.weight\n",
            "videomae.encoder.layer.10.attention.output.dense.weight\n",
            "videomae.encoder.layer.10.attention.output.dense.bias\n",
            "videomae.encoder.layer.10.intermediate.dense.weight\n",
            "videomae.encoder.layer.10.intermediate.dense.bias\n",
            "videomae.encoder.layer.10.output.dense.weight\n",
            "videomae.encoder.layer.10.output.dense.bias\n",
            "videomae.encoder.layer.10.layernorm_before.weight\n",
            "videomae.encoder.layer.10.layernorm_before.bias\n",
            "videomae.encoder.layer.10.layernorm_after.weight\n",
            "videomae.encoder.layer.10.layernorm_after.bias\n",
            "videomae.encoder.layer.11.attention.attention.q_bias\n",
            "videomae.encoder.layer.11.attention.attention.v_bias\n",
            "videomae.encoder.layer.11.attention.attention.query.weight\n",
            "videomae.encoder.layer.11.attention.attention.key.weight\n",
            "videomae.encoder.layer.11.attention.attention.value.weight\n",
            "videomae.encoder.layer.11.attention.output.dense.weight\n",
            "videomae.encoder.layer.11.attention.output.dense.bias\n",
            "videomae.encoder.layer.11.intermediate.dense.weight\n",
            "videomae.encoder.layer.11.intermediate.dense.bias\n",
            "videomae.encoder.layer.11.output.dense.weight\n",
            "videomae.encoder.layer.11.output.dense.bias\n",
            "videomae.encoder.layer.11.layernorm_before.weight\n",
            "videomae.encoder.layer.11.layernorm_before.bias\n",
            "videomae.encoder.layer.11.layernorm_after.weight\n",
            "videomae.encoder.layer.11.layernorm_after.bias\n",
            "fc_norm.weight\n",
            "fc_norm.bias\n",
            "classifier.weight\n",
            "classifier.bias\n"
          ]
        }
      ],
      "source": [
        "# model.classifier = model.classifier.to(dtype=torch.float32)\n",
        "# model.videomae.encoder.layer[-1] = model.videomae.encoder.layer[-1].to(dtype=torch.float32)\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rFga0GvMgxd2"
      },
      "outputs": [],
      "source": [
        "model.enable_input_require_grads()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XYsyy-l0Nm8J"
      },
      "outputs": [],
      "source": [
        "model_name = model_ckpt.split(\"/\")[-1]\n",
        "new_model_name = f\"{model_name}-finetuned-coin_domains-112\"\n",
        "num_epochs = 15\n",
        "batch_size = 32\n",
        "\n",
        "args = TrainingArguments(\n",
        "    new_model_name,\n",
        "    remove_unused_columns=False,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    max_steps=(train_dataset.num_videos // batch_size) * num_epochs,\n",
        "    seed=42,\n",
        "    dataloader_num_workers=10,\n",
        "\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.05,\n",
        "    max_grad_norm=1,\n",
        "    # optim=\"adafactor\",\n",
        "\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    # warmup_ratio=0.02,\n",
        "\n",
        "    fp16=True, # torch.float16 wieghts\n",
        "    gradient_checkpointing=False,\n",
        "    # gradient_accumulation_steps: 1\n",
        "\n",
        "    # evaluation_strategy=\"no\",\n",
        "    eval_steps=train_dataset.num_videos // batch_size * 5,\n",
        "    evaluation_strategy=\"steps\",\n",
        "\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=train_dataset.num_videos // batch_size *5,\n",
        "\n",
        "    # save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    save_total_limit=2,\n",
        "    hub_model_id='Myashka/videomae-base-coin-domains-no_mixup-112',\n",
        "    push_to_hub=True,\n",
        "\n",
        "    logging_steps=1,\n",
        "    report_to='wandb',\n",
        "    run_name=\"train-videomae-domains-lr5e_5-no_mixup-bs_128-rnd_val\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1O6-IEGR-O-D"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=image_processor,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kLz-mOgzD8rF"
      },
      "outputs": [],
      "source": [
        "model.gradient_checkpointing_enable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qz0513uQDaj4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
        "    model = torch.compile(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_results = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "th46gy0r-RPC",
        "outputId": "957224c7-ca80-45b7-871e-91b5b32f23ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmyashka\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/root/ITMO_DL_Tech_video_classification/notebooks/wandb/run-20231128_213829-23r1867y</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/myashka/ITMO_Video_lab/runs/23r1867y' target=\"_blank\">train-videomae-domains-lr5e_5-no_mixup-bs_128-rnd_val</a></strong> to <a href='https://wandb.ai/myashka/ITMO_Video_lab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/myashka/ITMO_Video_lab' target=\"_blank\">https://wandb.ai/myashka/ITMO_Video_lab</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/myashka/ITMO_Video_lab/runs/23r1867y' target=\"_blank\">https://wandb.ai/myashka/ITMO_Video_lab/runs/23r1867y</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [360/360 59:59, Epoch 11/9223372036854775807]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>2.087000</td>\n",
              "      <td>2.260927</td>\n",
              "      <td>0.268775</td>\n",
              "      <td>0.268775</td>\n",
              "      <td>0.268775</td>\n",
              "      <td>0.268775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>2.031000</td>\n",
              "      <td>2.005624</td>\n",
              "      <td>0.339921</td>\n",
              "      <td>0.339921</td>\n",
              "      <td>0.339921</td>\n",
              "      <td>0.339921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.876100</td>\n",
              "      <td>1.848167</td>\n",
              "      <td>0.367589</td>\n",
              "      <td>0.367589</td>\n",
              "      <td>0.367589</td>\n",
              "      <td>0.367589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>1.617100</td>\n",
              "      <td>1.762735</td>\n",
              "      <td>0.387352</td>\n",
              "      <td>0.387352</td>\n",
              "      <td>0.387352</td>\n",
              "      <td>0.387352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.251500</td>\n",
              "      <td>1.817730</td>\n",
              "      <td>0.418972</td>\n",
              "      <td>0.418972</td>\n",
              "      <td>0.418972</td>\n",
              "      <td>0.418972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>1.525800</td>\n",
              "      <td>1.649473</td>\n",
              "      <td>0.430830</td>\n",
              "      <td>0.430830</td>\n",
              "      <td>0.430830</td>\n",
              "      <td>0.430830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>1.091800</td>\n",
              "      <td>1.747039</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.434783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>1.142900</td>\n",
              "      <td>1.719501</td>\n",
              "      <td>0.442688</td>\n",
              "      <td>0.442688</td>\n",
              "      <td>0.442688</td>\n",
              "      <td>0.442688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>0.954500</td>\n",
              "      <td>1.528909</td>\n",
              "      <td>0.482213</td>\n",
              "      <td>0.482213</td>\n",
              "      <td>0.482213</td>\n",
              "      <td>0.482213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.704300</td>\n",
              "      <td>1.521585</td>\n",
              "      <td>0.498024</td>\n",
              "      <td>0.498024</td>\n",
              "      <td>0.498024</td>\n",
              "      <td>0.498024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>264</td>\n",
              "      <td>1.436500</td>\n",
              "      <td>1.607336</td>\n",
              "      <td>0.501976</td>\n",
              "      <td>0.501976</td>\n",
              "      <td>0.501976</td>\n",
              "      <td>0.501976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>288</td>\n",
              "      <td>1.076100</td>\n",
              "      <td>1.601661</td>\n",
              "      <td>0.498024</td>\n",
              "      <td>0.498024</td>\n",
              "      <td>0.498024</td>\n",
              "      <td>0.498024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>312</td>\n",
              "      <td>1.119600</td>\n",
              "      <td>1.499409</td>\n",
              "      <td>0.490119</td>\n",
              "      <td>0.490119</td>\n",
              "      <td>0.490119</td>\n",
              "      <td>0.490119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>336</td>\n",
              "      <td>1.120500</td>\n",
              "      <td>1.513620</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.521739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.908400</td>\n",
              "      <td>1.566272</td>\n",
              "      <td>0.494071</td>\n",
              "      <td>0.494071</td>\n",
              "      <td>0.494071</td>\n",
              "      <td>0.494071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-24)... Done. 1.5s\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-48)... Done. 1.5s\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-72)... Done. 1.5s\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-96)... Done. 2.8s\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-120)... Done. 1.6s\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-144)... Done. 1.7s\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-168)... Done. 1.5s\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-192)... Done. 2.7s\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-216)... Done. 2.5s\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-240)... Done. 1.6s\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-264)... Done. 1.5s\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-288)... Done. 2.6s\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-312)... Done. 1.7s\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-336)... Done. 2.7s\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./videomae-base-finetuned-coin_domains-112/checkpoint-360)... Done. 1.8s\n"
          ]
        }
      ],
      "source": [
        "train_results = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W7QdkFh-Vbh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TtufgwN-WG_L"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "027b16d7da0c48c5a46de46f32550ebb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04321b9477b649eaa7f738e3a6da84a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05e80d2e20ed4e2abcd439058f60f971": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11519a296deb4b8d844096340246ca4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "164a753ddf594b37bb4ad9ece7b291de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18a1811e259f411584bbb7e188470878": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a82fe71bda54ec38e3134e6c828c2c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aa64526684d4f4e9617e3c5de9dd9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c7e434be8f54bb19430b0554d6cdbc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23fb2075cf8e46d28996f84175f7d120": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "251a77c309a74517a351a28a030a2335": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2843b0d1ed0945cc8def7a9bbc04ec98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b5475dce1ba49f3b34bd5faffe4a576",
            "placeholder": "​",
            "style": "IPY_MODEL_164a753ddf594b37bb4ad9ece7b291de",
            "value": " 6.77k/6.77k [00:00&lt;00:00, 194kB/s]"
          }
        },
        "2b7e94237f574e6a97498cba9e5bd798": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f95154f9023414caea9921833e61db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18a1811e259f411584bbb7e188470878",
            "placeholder": "​",
            "style": "IPY_MODEL_04321b9477b649eaa7f738e3a6da84a8",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "30513adbebbb4c1eaf03120ffdd98c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b5475dce1ba49f3b34bd5faffe4a576": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42f4e6c969504bc6b5b0b691505c8ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "455d1afe2fd54f23a01c3cb73b9fa16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67287112196c4f199b87117490e463be",
            "placeholder": "​",
            "style": "IPY_MODEL_1aa64526684d4f4e9617e3c5de9dd9b7",
            "value": " 7.36k/7.36k [00:00&lt;00:00, 165kB/s]"
          }
        },
        "5041c2d4be1840c59a72c93ded2a7857": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "506761dd1d85471b8f73fc07fbe5eb93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7aab1a2b0da64bf496e1e23e0fc2552b",
              "IPY_MODEL_db004e1b87b04aa98361b20cafe49e48",
              "IPY_MODEL_fe57d4e345824755ba9da003b2496b81"
            ],
            "layout": "IPY_MODEL_dd36a048c4984354a3d3242271ded2eb"
          }
        },
        "58712dabfef24eb9835a3fbd1e54845d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc7da12d370f48ab952ef4f922b502c7",
              "IPY_MODEL_f105eb1da0fb44f5a39ed92bbd327f57",
              "IPY_MODEL_2843b0d1ed0945cc8def7a9bbc04ec98"
            ],
            "layout": "IPY_MODEL_11519a296deb4b8d844096340246ca4b"
          }
        },
        "60668640dbf14745a79a1724c73676e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d229a5af4a67402aa814744dc47eb9a7",
            "max": 271,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e73941a8a36446fd9e312a0aeff505a2",
            "value": 271
          }
        },
        "67287112196c4f199b87117490e463be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68cd1222ff9342c69e2e0463d532eece": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0e25554548447c4b104affd8c3c9d5b",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adad6ac7dd424726a1e462d8715cc421",
            "value": 4203
          }
        },
        "6c2dafd262e7426ab627e77f0ea3613a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c358a8c61eb457cb2eb4cff64eea8af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a20c1548c2a646649031657d9026f261",
            "placeholder": "​",
            "style": "IPY_MODEL_7e262ccea14d4a88aeba43ccc1a30b5a",
            "value": " 271/271 [00:00&lt;00:00, 10.4kB/s]"
          }
        },
        "6f211880114245929256e35b2314e594": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f980a3f470b44ff9cc3406842214427": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7662a9be4ddc4914820bea466a5c0c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e90da3ea3976461d998d51d729bf38fe",
            "max": 7363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb780556aa8341b48c6dd6345174a40a",
            "value": 7363
          }
        },
        "7aab1a2b0da64bf496e1e23e0fc2552b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd88a07c1ac64ac7b6833e3acda081a5",
            "placeholder": "​",
            "style": "IPY_MODEL_990864af312e4c45b1688a179657b549",
            "value": "Downloading builder script: 100%"
          }
        },
        "7e262ccea14d4a88aeba43ccc1a30b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c80069bdbc04e70a3b2e27371de5599": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e7544525d3b460387090654afeaf86d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a47b4b36108c4306ad4cfc9040124d8d",
              "IPY_MODEL_60668640dbf14745a79a1724c73676e7",
              "IPY_MODEL_6c358a8c61eb457cb2eb4cff64eea8af"
            ],
            "layout": "IPY_MODEL_251a77c309a74517a351a28a030a2335"
          }
        },
        "90df514de1a4453aadaa94b41ede6321": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91f23da2987d42b1829218bc9a156839": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5041c2d4be1840c59a72c93ded2a7857",
            "placeholder": "​",
            "style": "IPY_MODEL_befa5ba440b0426ab189b2f53d22c134",
            "value": " 377M/377M [00:03&lt;00:00, 86.5MB/s]"
          }
        },
        "97667e143c4a4b048811cc7a84ee74c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "990864af312e4c45b1688a179657b549": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0e25554548447c4b104affd8c3c9d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a20c1548c2a646649031657d9026f261": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a47b4b36108c4306ad4cfc9040124d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d61dea3231064c2d94ebed59fa6ee66a",
            "placeholder": "​",
            "style": "IPY_MODEL_05e80d2e20ed4e2abcd439058f60f971",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "adad6ac7dd424726a1e462d8715cc421": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae04bac7cac54b32a5c2ddf350dd1ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c442e80d94334615bc94b25a776894f7",
              "IPY_MODEL_7662a9be4ddc4914820bea466a5c0c16",
              "IPY_MODEL_455d1afe2fd54f23a01c3cb73b9fa16e"
            ],
            "layout": "IPY_MODEL_c59875cce0424b0e80e81c41639cc195"
          }
        },
        "b37c24d7a5924eb9a90343f848e3cb76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "befa5ba440b0426ab189b2f53d22c134": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c442e80d94334615bc94b25a776894f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef6dceb2f45543efa73bb6f9d2c5a124",
            "placeholder": "​",
            "style": "IPY_MODEL_2b7e94237f574e6a97498cba9e5bd798",
            "value": "Downloading builder script: 100%"
          }
        },
        "c59875cce0424b0e80e81c41639cc195": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbcce07dd5504cb6a0b477a323522984": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cec437841a924e1baa4858498868bf80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f95154f9023414caea9921833e61db0",
              "IPY_MODEL_fcc1675ee5604a90ac7327dd889be3cc",
              "IPY_MODEL_91f23da2987d42b1829218bc9a156839"
            ],
            "layout": "IPY_MODEL_e49c4e279ec447a8afa1a1ad88df0fb0"
          }
        },
        "d229a5af4a67402aa814744dc47eb9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4257ae2406a46cd8de56343b113ab72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e54ebd8ee7ba4c57a02677d4d3ec00ec",
              "IPY_MODEL_68cd1222ff9342c69e2e0463d532eece",
              "IPY_MODEL_ff2dae68d156444fa75285138b4ada8d"
            ],
            "layout": "IPY_MODEL_6c2dafd262e7426ab627e77f0ea3613a"
          }
        },
        "d61dea3231064c2d94ebed59fa6ee66a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84b39329eae493680f78e6306b6caf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db004e1b87b04aa98361b20cafe49e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbcce07dd5504cb6a0b477a323522984",
            "max": 7546,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42f4e6c969504bc6b5b0b691505c8ba2",
            "value": 7546
          }
        },
        "dc7da12d370f48ab952ef4f922b502c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b37c24d7a5924eb9a90343f848e3cb76",
            "placeholder": "​",
            "style": "IPY_MODEL_6f980a3f470b44ff9cc3406842214427",
            "value": "Downloading builder script: 100%"
          }
        },
        "dd36a048c4984354a3d3242271ded2eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd88a07c1ac64ac7b6833e3acda081a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e49c4e279ec447a8afa1a1ad88df0fb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e54ebd8ee7ba4c57a02677d4d3ec00ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c7e434be8f54bb19430b0554d6cdbc9",
            "placeholder": "​",
            "style": "IPY_MODEL_d84b39329eae493680f78e6306b6caf0",
            "value": "Downloading builder script: 100%"
          }
        },
        "e73941a8a36446fd9e312a0aeff505a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e90da3ea3976461d998d51d729bf38fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb780556aa8341b48c6dd6345174a40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef6dceb2f45543efa73bb6f9d2c5a124": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f105eb1da0fb44f5a39ed92bbd327f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a82fe71bda54ec38e3134e6c828c2c1",
            "max": 6771,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c80069bdbc04e70a3b2e27371de5599",
            "value": 6771
          }
        },
        "fcc1675ee5604a90ac7327dd889be3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_027b16d7da0c48c5a46de46f32550ebb",
            "max": 376924301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f211880114245929256e35b2314e594",
            "value": 376924301
          }
        },
        "fe57d4e345824755ba9da003b2496b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90df514de1a4453aadaa94b41ede6321",
            "placeholder": "​",
            "style": "IPY_MODEL_23fb2075cf8e46d28996f84175f7d120",
            "value": " 7.55k/7.55k [00:00&lt;00:00, 167kB/s]"
          }
        },
        "ff2dae68d156444fa75285138b4ada8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97667e143c4a4b048811cc7a84ee74c9",
            "placeholder": "​",
            "style": "IPY_MODEL_30513adbebbb4c1eaf03120ffdd98c09",
            "value": " 4.20k/4.20k [00:00&lt;00:00, 64.5kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
